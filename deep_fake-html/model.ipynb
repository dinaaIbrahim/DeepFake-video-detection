{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f46ddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import pickle\n",
    "import sklearn\n",
    "import cvlib as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer, GlobalAveragePooling2D\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from tensorflow.keras.applications import ResNet50, InceptionResNetV2, MobileNetV2, VGG16\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,KFold\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.applications import ResNet50,InceptionResNetV2\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from skmultilearn.model_selection import IterativeStratification\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from sklearn.metrics import classification_report \n",
    "from tensorflow.keras.applications import VGG16\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35688f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the pre-trained soft voting model using pickle\n",
    "def load_soft_voting_model(model_file_path):\n",
    "    with open(model_file_path, 'rb') as model_file:\n",
    "        soft_voting_model = pickle.load(model_file)\n",
    "    return soft_voting_model['models']\n",
    "\n",
    "\n",
    "soft_voting_model_file_path = \"C:/Users/Project/Desktop/Deep_fake/DeepFake_Video_Detection/DeepFake_Video_Detection/deep_fake-html/soft_voting_results.pkl\"\n",
    "# Load the soft voting model\n",
    "loaded_soft_voting_model = load_soft_voting_model(soft_voting_model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec6f6e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capture one frame every 2 seconds\n",
      "Total number of frames: 5\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "Final Result:\n",
      "The video is classified as Real by 0.00% confidence.\n"
     ]
    }
   ],
   "source": [
    "# Function to process a single video, preprocess frames, and classify using a pre-loaded soft voting model\n",
    "def process_and_classify_video(video_path, frameTime, soft_voting_model):\n",
    "    ListFrames = []\n",
    "    video_ids = []\n",
    "    frame_ids = []\n",
    "\n",
    "    total_videos = 0\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_interval = int(frame_rate * frameTime)\n",
    "\n",
    "    frame_counter = 0\n",
    "    video_frame_ids = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_counter += 1\n",
    "\n",
    "        if frame_counter % frame_interval == 0:\n",
    "            frame = cv2.resize(frame, (128, 128))\n",
    "            ListFrames.append(frame)\n",
    "\n",
    "            video_ids.append(total_videos)\n",
    "            frame_ids.append(video_frame_ids)\n",
    "            video_frame_ids += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    data = {\n",
    "        'VideoID': video_ids,\n",
    "        'FrameID': frame_ids,\n",
    "        'Frames': ListFrames,\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    print(f\"Capture one frame every {frameTime} seconds\")\n",
    "    print(f\"Total number of frames: {len(df)}\")\n",
    "\n",
    "    # Preprocess frames\n",
    "    df['Frames'] = df['Frames'] / 255.0\n",
    "\n",
    "    # Classify videos based on each model in the loaded models\n",
    "    unique_videos = df['VideoID'].unique()\n",
    "    video_results_details = []\n",
    "\n",
    "    for model_index, model in enumerate(soft_voting_model):\n",
    "        model_results = []\n",
    "\n",
    "        for vid in unique_videos:\n",
    "            video_subset = df[df['VideoID'] == vid]\n",
    "            X_video = tf.convert_to_tensor(np.array(video_subset['Frames'].tolist()), dtype=tf.float32)\n",
    "\n",
    "            # Make predictions using the current model\n",
    "            predictions = model.predict(X_video)\n",
    "\n",
    "            # Count the occurrences of predicted labels\n",
    "            count_fake = np.sum(predictions == 0)  # Assuming 0 corresponds to 'Fake' in the model\n",
    "\n",
    "            # Determine the model decision ('Real' or 'Fake') based on the count of 'Fake' frames\n",
    "            total_count = len(video_subset)\n",
    "            if count_fake / total_count >= 0.3:\n",
    "                result = 'Fake'\n",
    "            else:\n",
    "                result = 'Real'\n",
    "\n",
    "            percentage_fake = (count_fake / total_count) * 100\n",
    "            model_results.append((vid, result, percentage_fake))\n",
    "\n",
    "        video_results_details.append(model_results)\n",
    "\n",
    "    # Apply soft voting to the individual predictions from each model\n",
    "    soft_voting_results = []\n",
    "\n",
    "    for i in range(len(unique_videos)):\n",
    "        video_id = unique_videos[i]\n",
    "        video_results = [model_results[i] for model_results in video_results_details]\n",
    "\n",
    "        # Soft voting: sum up the individual predictions for each video\n",
    "        avg_prediction = np.mean([result[1] == 'Fake' for result in video_results])\n",
    "\n",
    "        # Determine the soft voting decision ('Real' or 'Fake') based on label proportions\n",
    "        if avg_prediction >= 0.5:  # Assuming 0.5 as the threshold for 'Fake' in soft voting\n",
    "            result = 'Fake'\n",
    "        else:\n",
    "            result = 'Real'\n",
    "\n",
    "        confidence_percentage = avg_prediction * 100\n",
    "        soft_voting_results.append((video_id, result, confidence_percentage))\n",
    "\n",
    "    # Determine the final result based on the soft voting decision\n",
    "    final_result = 'Fake' if any(result == 'Fake' for _, result, _ in soft_voting_results) else 'Real'\n",
    "\n",
    "    # Display the final result with confidence percentage\n",
    "    print(\"\\nFinal Result:\")\n",
    "    print(f\"The video is classified as {final_result} by {confidence_percentage:.2f}% confidence.\")\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "video_path = \"C:/Users/Project/Desktop/adaoqecjet.mp4\"\n",
    "frame_time_seconds = 2\n",
    "# Process and classify the video using the loaded soft voting model\n",
    "process_and_classify_video(video_path, frame_time_seconds, loaded_soft_voting_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befdac04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524ad1f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e46d71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11b708e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capture one frame every 2 seconds\n",
      "Total number of frames: 5\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "\n",
      "Individual Model Decisions:\n",
      "Results for Model 1:\n",
      "  Video ID 0: Real, Percentage Fake: 0.00%\n",
      "Results for Model 2:\n",
      "  Video ID 0: Real, Percentage Fake: 0.00%\n",
      "Results for Model 3:\n",
      "  Video ID 0: Real, Percentage Fake: 0.00%\n",
      "\n",
      "Final Result:\n",
      "The video is classified as Real by 0.00% confidence.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Function to process a single video, preprocess frames, and classify using a pre-loaded soft voting model\n",
    "def process_and_classify_video(video_path, frameTime, soft_voting_model):\n",
    "    ListFrames = []\n",
    "    video_ids = []\n",
    "    frame_ids = []\n",
    "\n",
    "    total_videos = 0\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_interval = int(frame_rate * frameTime)\n",
    "\n",
    "    frame_counter = 0\n",
    "    video_frame_ids = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_counter += 1\n",
    "\n",
    "        if frame_counter % frame_interval == 0:\n",
    "            frame = cv2.resize(frame, (128, 128))\n",
    "            ListFrames.append(frame)\n",
    "\n",
    "            video_ids.append(total_videos)\n",
    "            frame_ids.append(video_frame_ids)\n",
    "            video_frame_ids += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    data = {\n",
    "        'VideoID': video_ids,\n",
    "        'FrameID': frame_ids,\n",
    "        'Frames': ListFrames,\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    print(f\"Capture one frame every {frameTime} seconds\")\n",
    "    print(f\"Total number of frames: {len(df)}\")\n",
    "\n",
    "    # Preprocess frames\n",
    "    df['Frames'] = df['Frames'] / 255.0\n",
    "\n",
    "    # Classify videos based on each model in the loaded models\n",
    "    unique_videos = df['VideoID'].unique()\n",
    "    video_results_details = []\n",
    "\n",
    "    for model_index, model in enumerate(soft_voting_model):\n",
    "        model_results = []\n",
    "\n",
    "        for vid in unique_videos:\n",
    "            video_subset = df[df['VideoID'] == vid]\n",
    "            X_video = tf.convert_to_tensor(np.array(video_subset['Frames'].tolist()), dtype=tf.float32)\n",
    "\n",
    "            # Make predictions using the current model\n",
    "            predictions = model.predict(X_video)\n",
    "\n",
    "            # Count the occurrences of predicted labels\n",
    "            count_fake = np.sum(predictions == 0)  # Assuming 0 corresponds to 'Fake' in the model\n",
    "\n",
    "            # Determine the model decision ('Real' or 'Fake') based on the count of 'Fake' frames\n",
    "            total_count = len(video_subset)\n",
    "            if count_fake / total_count >= 0.3:\n",
    "                result = 'Fake'\n",
    "            else:\n",
    "                result = 'Real'\n",
    "\n",
    "            percentage_fake = (count_fake / total_count) * 100\n",
    "            model_results.append((vid, result, percentage_fake))\n",
    "\n",
    "        video_results_details.append(model_results)\n",
    "\n",
    "    # Print individual model decisions\n",
    "    print(\"\\nIndividual Model Decisions:\")\n",
    "    for model_index, model_results in enumerate(video_results_details):\n",
    "        print(f\"Results for Model {model_index + 1}:\")\n",
    "        for vid, result, percentage_fake in model_results:\n",
    "            print(f\"  Video ID {vid}: {result}, Percentage Fake: {percentage_fake:.2f}%\")\n",
    "\n",
    "    # Apply soft voting to the individual predictions from each model\n",
    "    soft_voting_results = []\n",
    "\n",
    "    for i in range(len(unique_videos)):\n",
    "        video_id = unique_videos[i]\n",
    "        video_results = [model_results[i] for model_results in video_results_details]\n",
    "\n",
    "        # Soft voting: sum up the individual predictions for each video\n",
    "        avg_prediction = np.mean([result[1] == 'Fake' for result in video_results])\n",
    "\n",
    "        # Determine the soft voting decision ('Real' or 'Fake') based on label proportions\n",
    "        if avg_prediction >= 0.5:  # Assuming 0.5 as the threshold for 'Fake' in soft voting\n",
    "            result = 'Fake'\n",
    "        else:\n",
    "            result = 'Real'\n",
    "\n",
    "        confidence_percentage = avg_prediction * 100\n",
    "        soft_voting_results.append((video_id, result, confidence_percentage))\n",
    "\n",
    "    # Determine the final result based on the soft voting decision\n",
    "    final_result = 'Fake' if any(result == 'Fake' for _, result, _ in soft_voting_results) else 'Real'\n",
    "\n",
    "    # Display the final result with confidence percentage\n",
    "    print(\"\\nFinal Result:\")\n",
    "    for vid, result, confidence_percentage in soft_voting_results:\n",
    "        print(f\"The video is classified as {result} by {confidence_percentage:.2f}% confidence.\")\n",
    "\n",
    "# Example usage\n",
    "video_path = \"C:/Users/Project/Desktop/adaoqecjet.mp4\"\n",
    "frame_time_seconds = 2\n",
    "# Load the soft voting model\n",
    "\n",
    "# Process and classify the video using the loaded soft voting model\n",
    "process_and_classify_video(video_path, frame_time_seconds, loaded_soft_voting_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5716ba1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa9072e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capture one frame every 2 seconds\n",
      "Total number of frames: 5\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "\n",
      "Final Result:\n",
      "The video is classified as Fake by 0.00% confidence.\n"
     ]
    }
   ],
   "source": [
    "# Function to process a single video, preprocess frames, and classify using a pre-loaded soft voting model\n",
    "def process_and_classify_video(video_path, frameTime, soft_voting_model):\n",
    "    ListFrames = []\n",
    "    video_ids = []\n",
    "    frame_ids = []\n",
    "\n",
    "    total_videos = 0\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_interval = int(frame_rate * frameTime)\n",
    "\n",
    "    frame_counter = 0\n",
    "    video_frame_ids = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_counter += 1\n",
    "\n",
    "        if frame_counter % frame_interval == 0:\n",
    "            frame = cv2.resize(frame, (128, 128))\n",
    "            ListFrames.append(frame)\n",
    "\n",
    "            video_ids.append(total_videos)\n",
    "            frame_ids.append(video_frame_ids)\n",
    "            video_frame_ids += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    data = {\n",
    "        'VideoID': video_ids,\n",
    "        'FrameID': frame_ids,\n",
    "        'Frames': ListFrames,\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    print(f\"Capture one frame every {frameTime} seconds\")\n",
    "    print(f\"Total number of frames: {len(df)}\")\n",
    "\n",
    "    # Preprocess frames\n",
    "    df['Frames'] = df['Frames'] / 255.0\n",
    "\n",
    "    # Classify videos based on each model in the loaded models\n",
    "    unique_videos = df['VideoID'].unique()\n",
    "    video_results_details = []\n",
    "\n",
    "    for model_index, model in enumerate(soft_voting_model):\n",
    "        model_results = []\n",
    "\n",
    "        for vid in unique_videos:\n",
    "            video_subset = df[df['VideoID'] == vid]\n",
    "            X_video = tf.convert_to_tensor(np.array(video_subset['Frames'].tolist()), dtype=tf.float32)\n",
    "\n",
    "            # Make predictions using the current model\n",
    "            predictions = model.predict(X_video)\n",
    "\n",
    "            # Count the occurrences of predicted labels\n",
    "            count_real = np.sum(predictions == 1)  # Assuming 1 corresponds to 'Real' in the model\n",
    "\n",
    "            # Determine the model decision ('Real' or 'Fake') based on the count of 'Real' frames\n",
    "            total_count = len(video_subset)\n",
    "            percentage_real = (count_real / total_count) * 100\n",
    "            model_results.append((vid, percentage_real))\n",
    "\n",
    "        video_results_details.append(model_results)\n",
    "\n",
    "    # Apply soft voting to the individual predictions from each model\n",
    "    soft_voting_results = []\n",
    "\n",
    "    for i in range(len(unique_videos)):\n",
    "        video_id = unique_videos[i]\n",
    "        video_results = [model_results[i] for model_results in video_results_details]\n",
    "\n",
    "        # Soft voting: sum up the individual predictions for each video\n",
    "        avg_prediction = np.mean([result[1] for result in video_results])  # Assuming index 1 corresponds to 'Real' percentage\n",
    "\n",
    "        # Determine the soft voting decision ('Real' or 'Fake') based on label proportions\n",
    "        if avg_prediction >= 50.0:  # Assuming 50.0 as the threshold for 'Real' in soft voting\n",
    "            result = 'Real'\n",
    "        else:\n",
    "            result = 'Fake'\n",
    "\n",
    "        confidence_percentage = avg_prediction\n",
    "\n",
    "        soft_voting_results.append((video_id, result, confidence_percentage))\n",
    "\n",
    "    # Display the final result with confidence percentage\n",
    "    print(\"\\nFinal Result:\")\n",
    "    for vid, result, confidence_percentage in soft_voting_results:\n",
    "        print(f\"The video is classified as {result} by {confidence_percentage:.2f}% confidence.\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "video_path = \"C:/Users/Project/Desktop/adaoqecjet.mp4\"\n",
    "frame_time_seconds = 2\n",
    "# Process and classify the video using the loaded soft voting model\n",
    "process_and_classify_video(video_path, frame_time_seconds, loaded_soft_voting_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
