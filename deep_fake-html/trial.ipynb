{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccc56a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Project\\anaconda3\\envs\\nade\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import pickle\n",
    "import sklearn\n",
    "import cvlib as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer, GlobalAveragePooling2D\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from tensorflow.keras.applications import ResNet50, InceptionResNetV2, MobileNetV2, VGG16\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,KFold\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.applications import ResNet50,InceptionResNetV2\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from skmultilearn.model_selection import IterativeStratification\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from sklearn.metrics import classification_report \n",
    "from tensorflow.keras.applications import VGG16\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a72970f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the pre-trained soft voting model using pickle\n",
    "def load_soft_voting_model(model_file_path):\n",
    "    with open(model_file_path, 'rb') as model_file:\n",
    "        soft_voting_model = pickle.load(model_file)\n",
    "    return soft_voting_model['model']\n",
    "\n",
    "InceptionResNetV2_model_file_path = \"C:/Users/Project/Desktop/DeepFake_Video_Detection/DeepFake_Video_Detection/DeepFake_Video_Detection/deep_fake-html/MobileNetV2_model_history.pkl\"\n",
    "# Load the soft voting model\n",
    "loaded_InceptionResNetV2_model = load_soft_voting_model(InceptionResNetV2_model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a188581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_video(video_path, frameTime):\n",
    "    # Initialize lists to store frame data, video IDs, and frame IDs\n",
    "    ListFrames = []\n",
    "    video_ids = []\n",
    "    frame_ids = []\n",
    "\n",
    "    total_videos = 0\n",
    "\n",
    "    # Load the video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_rate = cap.get(cv2.CAP_PROP_FPS)  # Get the video's frame rate\n",
    "    frame_interval = int(frame_rate * frameTime)  # Calculate the frame capture interval\n",
    "\n",
    "    frame_counter = 0\n",
    "    video_frame_ids = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # Break if there are no more frames\n",
    "\n",
    "        frame_counter += 1\n",
    "\n",
    "        # Capture frames at the specified interval\n",
    "        if frame_counter % frame_interval == 0:\n",
    "            frame = cv2.resize(frame, (128, 128))  # Resize frames to 128x128\n",
    "            ListFrames.append(frame)\n",
    "            video_ids.append(total_videos)\n",
    "            frame_ids.append(video_frame_ids)\n",
    "            video_frame_ids += 1  # Increment frame ID for the video\n",
    "\n",
    "    cap.release()  # Release video capture object after processing\n",
    "\n",
    "    # Create a DataFrame from collected data\n",
    "    data = {\n",
    "        'VideoID': video_ids,\n",
    "        'FrameID': frame_ids,\n",
    "        'Frames': ListFrames,\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Print summary information\n",
    "    # print(f\"Capture one frame every {frameTime} seconds\")\n",
    "    # print(f\"Total number of frames: {len(df)}\")\n",
    "\n",
    "    return df  # Return the DataFrame containing video frame information\n",
    "\n",
    "# Example usage\n",
    "# video_path = \"C:/Users/Project/Desktop/fake.mp4\"\n",
    "# frame_time_seconds = 2\n",
    "# processed_df = process_single_video(video_path, frame_time_seconds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18aa016d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VideoID</th>\n",
       "      <th>FrameID</th>\n",
       "      <th>Frames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[[157, 189, 209], [151, 186, 210], [151, 186,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[151, 183, 210], [154, 181, 209], [152, 182,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[[[155, 183, 208], [155, 182, 210], [161, 184,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[[[154, 184, 209], [152, 184, 211], [154, 184,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[[[150, 184, 206], [155, 184, 207], [156, 184,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VideoID  FrameID                                             Frames\n",
       "0        0        0  [[[157, 189, 209], [151, 186, 210], [151, 186,...\n",
       "1        0        1  [[[151, 183, 210], [154, 181, 209], [152, 182,...\n",
       "2        0        2  [[[155, 183, 208], [155, 182, 210], [161, 184,...\n",
       "3        0        3  [[[154, 184, 209], [152, 184, 211], [154, 184,...\n",
       "4        0        4  [[[150, 184, 206], [155, 184, 207], [156, 184,..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70fac7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_frames(df):\n",
    "    np_ListFrames = np.array(df['Frames'])\n",
    "\n",
    "    # Normalize the pixel values to be in the range [0, 1]\n",
    "    np_ListFrames = np_ListFrames / 255.0\n",
    "\n",
    "    # Add a new column to the existing DataFrame\n",
    "    df['Normalized Frames'] = list(np_ListFrames)\n",
    "\n",
    "    return df\n",
    "\n",
    "# # Example usage\n",
    "# normalized_df = normalize_frames(processed_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e95dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalized_df=normalized_df[['VideoID','FrameID','Normalized Frames']]\n",
    "#normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3790040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 625ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    }
   ],
   "source": [
    "def classify_frames(df, model):\n",
    "    np_normalized_frames = np.array(df['Normalized Frames'])\n",
    "    predictions = []\n",
    "\n",
    "    # Iterate through each normalized frame and make predictions\n",
    "    for normalized_frame in np_normalized_frames:\n",
    "        X_frame = np.expand_dims(normalized_frame, axis=0)  # Add batch dimension\n",
    "        prediction = model.predict(X_frame)[0]  # Assuming binary output\n",
    "        predictions.append(prediction)\n",
    "\n",
    "    # Add the predictions to the DataFrame\n",
    "    df['Predictions'] = predictions\n",
    "\n",
    "    return df\n",
    "\n",
    "# # Example usage\n",
    "# # Assuming 'your_pretrained_model' is the pre-trained model for real/fake classification\n",
    "# classified_df = classify_frames(normalized_df, loaded_InceptionResNetV2_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46055b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VideoID</th>\n",
       "      <th>FrameID</th>\n",
       "      <th>Frames</th>\n",
       "      <th>Normalized Frames</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[[157, 189, 209], [151, 186, 210], [151, 186,...</td>\n",
       "      <td>[[[0.615686274509804, 0.7411764705882353, 0.81...</td>\n",
       "      <td>[0.9992931, 0.0007069451]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[151, 183, 210], [154, 181, 209], [152, 182,...</td>\n",
       "      <td>[[[0.592156862745098, 0.7176470588235294, 0.82...</td>\n",
       "      <td>[0.99999774, 2.319536e-06]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[[[155, 183, 208], [155, 182, 210], [161, 184,...</td>\n",
       "      <td>[[[0.6078431372549019, 0.7176470588235294, 0.8...</td>\n",
       "      <td>[0.9997093, 0.00029069552]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[[[154, 184, 209], [152, 184, 211], [154, 184,...</td>\n",
       "      <td>[[[0.6039215686274509, 0.7215686274509804, 0.8...</td>\n",
       "      <td>[0.99989367, 0.000106339896]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[[[150, 184, 206], [155, 184, 207], [156, 184,...</td>\n",
       "      <td>[[[0.5882352941176471, 0.7215686274509804, 0.8...</td>\n",
       "      <td>[0.9987369, 0.0012631444]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VideoID  FrameID                                             Frames  \\\n",
       "0        0        0  [[[157, 189, 209], [151, 186, 210], [151, 186,...   \n",
       "1        0        1  [[[151, 183, 210], [154, 181, 209], [152, 182,...   \n",
       "2        0        2  [[[155, 183, 208], [155, 182, 210], [161, 184,...   \n",
       "3        0        3  [[[154, 184, 209], [152, 184, 211], [154, 184,...   \n",
       "4        0        4  [[[150, 184, 206], [155, 184, 207], [156, 184,...   \n",
       "\n",
       "                                   Normalized Frames  \\\n",
       "0  [[[0.615686274509804, 0.7411764705882353, 0.81...   \n",
       "1  [[[0.592156862745098, 0.7176470588235294, 0.82...   \n",
       "2  [[[0.6078431372549019, 0.7176470588235294, 0.8...   \n",
       "3  [[[0.6039215686274509, 0.7215686274509804, 0.8...   \n",
       "4  [[[0.5882352941176471, 0.7215686274509804, 0.8...   \n",
       "\n",
       "                    Predictions  \n",
       "0     [0.9992931, 0.0007069451]  \n",
       "1    [0.99999774, 2.319536e-06]  \n",
       "2    [0.9997093, 0.00029069552]  \n",
       "3  [0.99989367, 0.000106339896]  \n",
       "4     [0.9987369, 0.0012631444]  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classified_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a20b803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VideoID  FrameID                                             Frames  \\\n",
      "0        0        0  [[[157, 189, 209], [151, 186, 210], [151, 186,...   \n",
      "1        0        1  [[[151, 183, 210], [154, 181, 209], [152, 182,...   \n",
      "2        0        2  [[[155, 183, 208], [155, 182, 210], [161, 184,...   \n",
      "3        0        3  [[[154, 184, 209], [152, 184, 211], [154, 184,...   \n",
      "4        0        4  [[[150, 184, 206], [155, 184, 207], [156, 184,...   \n",
      "\n",
      "                                   Normalized Frames  \\\n",
      "0  [[[0.615686274509804, 0.7411764705882353, 0.81...   \n",
      "1  [[[0.592156862745098, 0.7176470588235294, 0.82...   \n",
      "2  [[[0.6078431372549019, 0.7176470588235294, 0.8...   \n",
      "3  [[[0.6039215686274509, 0.7215686274509804, 0.8...   \n",
      "4  [[[0.5882352941176471, 0.7215686274509804, 0.8...   \n",
      "\n",
      "                    Predictions  PredictedLabels  \n",
      "0     [0.9992931, 0.0007069451]                0  \n",
      "1    [0.99999774, 2.319536e-06]                0  \n",
      "2    [0.9997093, 0.00029069552]                0  \n",
      "3  [0.99989367, 0.000106339896]                0  \n",
      "4     [0.9987369, 0.0012631444]                0  \n"
     ]
    }
   ],
   "source": [
    "# # Apply argmax to 'Predictions' column and append the result as a new column\n",
    "# classified_df['PredictedLabels'] = np.argmax(classified_df['Predictions'].tolist(), axis=1)\n",
    "# # Display the modified DataFrame\n",
    "# print(classified_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02bc9dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The video is Fake  by 100.0%\n"
     ]
    }
   ],
   "source": [
    "# # Calculate the total number of frames for each video\n",
    "# video_frame_counts = classified_df['VideoID'].value_counts()\n",
    "\n",
    "# # Iterate through unique video IDs\n",
    "# for vid in classified_df['VideoID'].unique():\n",
    "#     video_subset = classified_df[classified_df['VideoID'] == vid]\n",
    "\n",
    "#     # Count the occurrences of predicted labels\n",
    "#     count_real = np.sum(video_subset['PredictedLabels'] == 1)  # Assuming 1 corresponds to 'Real' in the model\n",
    "\n",
    "#     # Calculate the percentage of 'Real' frames\n",
    "#     percentage_real = (count_real / video_frame_counts[vid]) * 100\n",
    "\n",
    "#     # Determine the model decision ('Real' or 'Fake') based on the percentage of 'Real' frames\n",
    "#     if percentage_real >= 70:\n",
    "#         result = 'Real'\n",
    "#         # Display the final results for 'Real' videos\n",
    "#         print(f\"The video is {result} by {percentage_real}%\")\n",
    "#     else:\n",
    "#         result = 'Fake'\n",
    "#         # Display the final results for 'Fake' videos\n",
    "#         print(f\"The video is {result}  by {100 - percentage_real}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f0ebf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_classify_video(video_path_new , frame_time_seconds=2):\n",
    "    processed_df = process_single_video(video_path_new, frame_time_seconds)\n",
    "    normalized_df = normalize_frames(processed_df)\n",
    "    classified_df = classify_frames(normalized_df, loaded_InceptionResNetV2_model)\n",
    "    classified_df['PredictedLabels'] = np.argmax(classified_df['Predictions'].tolist(), axis=1)\n",
    "    \n",
    "    video_frame_counts = classified_df['VideoID'].value_counts()\n",
    "\n",
    "    # Iterate through unique video IDs\n",
    "    for vid in classified_df['VideoID'].unique():\n",
    "        video_subset = classified_df[classified_df['VideoID'] == vid]\n",
    "\n",
    "        # Count the occurrences of predicted labels\n",
    "        count_real = np.sum(video_subset['PredictedLabels'] == 1)  # Assuming 1 corresponds to 'Real' in the model\n",
    "\n",
    "        # Calculate the percentage of 'Real' frames\n",
    "        percentage_real = (count_real / video_frame_counts[vid]) * 100\n",
    "\n",
    "        # Determine the model decision ('Real' or 'Fake') based on the percentage of 'Real' frames\n",
    "        if percentage_real >= 70:\n",
    "            result = 'Real'\n",
    "            # Display the final results for 'Real' videos\n",
    "            return (f\"The video is {result} by {percentage_real}%\")\n",
    "        else:\n",
    "            result = 'Fake'\n",
    "            # Display the final results for 'Fake' videos\n",
    "            return (f\"The video is {result}  by {100 - percentage_real}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
